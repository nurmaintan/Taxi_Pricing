# -*- coding: utf-8 -*-
"""taxi pricing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jgp1jqUS-ITXt3KU5pnms8Iy4HW_RXwP

# Proyek Predictive Analytics - Taxi Pricing

# Data Understanding

## Data Loading
Pada tahap ini, dataset dimuat menggunakan library pandas. Dataset yang digunakan adalah taxi_trip_pricing.csv.
"""

import pandas as pd

# Load the dataset
df = pd.read_csv('taxi_trip_pricing.csv')
df

"""- Ada 1000 baris (records atau jumlah pengamatan) dalam dataset.
- Terdapat 11 kolom yaitu: Trip_Distance_km,	Time_of_Day,	Day_of_Week,	Passenger_Count,	Traffic_Conditions,	Weather,	Base_Fare,	Per_Km_Rate,	Per_Minute_Rate,	Trip_Duration_Minutes,	Trip_Price.

## Exploratory Data Analysis - Deskripsi Variabel
Fungsi info() digunakan untuk mendapatkan informasi tentang dataset, termasuk jumlah baris, kolom, tipe data, dan jumlah nilai non-null.
"""

# Display dataset information
df.info()

"""- Terdapat 4 kolom dengan tipe object, yaitu: Time_of_Day,  Day_of_Week, Weather, Base_Fare. Kolom ini merupakan categorical features (fitur non-numerik).
- Terdapat 7 kolom numerik dengan tipe data float64 yaitu: Trip_Distance_km, Passenger_Count, Base_Fare, Per_Km_Rate, Per_Minute_Rate, Trip_Duration_Minutes, Trip_Price.
- Terdapat 1 kolom yang memiliki tipe data tidak sesuai yaitu: Passenger_Count.

### Mengubah Tipe Data yang Tidak Sesuai
Kolom Passenger_Count harus diubah dari float64 menjadi int64 karena jumlah penumpang adalah bilangan bulat. Namun, kolom Passenger_Count mengandung nilai yang tidak dapat dikonversi menjadi integer, seperti NaN (nilai yang hilang) atau infinit. Maka, perlu menangani nilai yang hilang terlebih dahulu sebelum mengonversinya ke tipe int64.
"""

# Imputasi nilai NaN pada 'Passenger_Count' dengan modus (nilai yang paling sering muncul)
df['Passenger_Count'] = df['Passenger_Count'].fillna(df['Passenger_Count'].mode()[0])

# Mengonversi kolom 'Passenger_Count' ke tipe integer
df['Passenger_Count'] = df['Passenger_Count'].astype('int64')

# Memeriksa tipe data setelah perubahan
df.info()

"""Fungsi describe() memberikan statistik deskriptif seperti mean, std, min, max, dan kuartil untuk setiap kolom numerik."""

# Display descriptive statistics
df.describe()

"""## Exploratory Data Analysis - Menangani Missing Value dan Outliers

### Menangani Missing Value

Kita memeriksa missing value dengan isnull().sum()
"""

# Check for missing values
df.isnull().sum()

"""Untuk Atribut Kategorikal:

- Time_of_Day: Menggunakan modus (nilai yang paling sering muncul) berdasarkan pola waktu yang umum
- Day_of_Week: Menggunakan modus karena ini adalah data kategorikal dengan nilai tetap
- Traffic_Conditions: Menggunakan modus kondisi lalu lintas pada Time_of_Day yang sama
- Weather: Menggunakan modus cuaca pada hari dan waktu yang sama
"""

# Mengimputasi missing value pada kolom kategorikal

df['Time_of_Day'] = df['Time_of_Day'].fillna(df['Time_of_Day'].mode()[0])
df['Day_of_Week'] = df['Day_of_Week'].fillna(df['Day_of_Week'].mode()[0])
df['Weather'] = df.groupby('Day_of_Week')['Weather'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Normal'))
df['Traffic_Conditions'] = df.groupby('Time_of_Day')['Traffic_Conditions'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'Normal')
    )

"""Untuk Atribut Numerik:

- Trip_Distance_km: Menggunakan median untuk imputasi karena jarak perjalanan biasanya memiliki distribusi yang skewed
- Passenger_Count: Menggunakan modus karena ini adalah data diskrit dengan nilai yang terbatas
- Base_Fare, Per_Km_Rate, Per_Minute_Rate: Menggunakan median untuk menghindari pengaruh outlier
- Trip_Duration_Minutes: Menggunakan median karena durasi perjalanan juga cenderung memiliki distribusi yang skewed
- Trip_Price: Dihitung ulang berdasarkan Base_Fare + (Per_Km_Rate × Trip_Distance_km) + (Per_Minute_Rate × Trip_Duration_Minutes)
"""

# Mengimputasi missing value pada kolom numerikal
df['Passenger_Count'] = df['Passenger_Count'].fillna(df['Passenger_Count'].mode()[0])
df['Trip_Distance_km'] = df['Trip_Distance_km'].fillna(df['Trip_Distance_km'].median())
df['Trip_Duration_Minutes'] = df['Trip_Duration_Minutes'].fillna(df['Trip_Duration_Minutes'].median())
numeric_cols = ['Base_Fare', 'Per_Km_Rate', 'Per_Minute_Rate']
for col in numeric_cols:
  df[col] = df[col].fillna(df[col].median())
price_missing_mask = df['Trip_Price'].isna()
df.loc[price_missing_mask, 'Trip_Price'] = (df.loc[price_missing_mask, 'Base_Fare'] +
 (df.loc[price_missing_mask, 'Per_Km_Rate'] * df.loc[price_missing_mask, 'Trip_Distance_km']) +
  (df.loc[price_missing_mask, 'Per_Minute_Rate'] * df.loc[price_missing_mask, 'Trip_Duration_Minutes']))

# Memeriksa apakah ada nilai hilang setelah imputasi atau penghapusan
df.isnull().sum()

"""### Duplicate Row"""

duplicate_rows = df[df.duplicated()]

if not duplicate_rows.empty:
    print("Duplicate Rows:")
    print(duplicate_rows)
else:
    print("No duplicate rows found.")

"""### Menangani Outliers

Outliers dapat dideteksi menggunakan boxplot dari library seaborn.
"""

# Check for outliers using boxplot
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
sns.boxplot(data=df)
plt.show()

df.shape

"""Pada beberapa fitur numerik di atas terdapat outliers. Outliers tersebut akan diatasi dengan mengganti outlier dengan nilai batas."""

df_numerik = df.select_dtypes(include=['number'])

Q1 = df_numerik.quantile(0.25)
Q3 = df_numerik.quantile(0.75)
IQR=Q3-Q1
df=df[~((df_numerik<(Q1-1.5*IQR))|(df_numerik>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
df.shape

"""## Exploratory Data Analysis - Univariate Analysis

Analisis univariate dilakukan untuk memahami distribusi data pada setiap kolom.
"""

# membagi fitur pada dataset

numerical_features = ['Trip_Distance_km', 'Passenger_Count', 'Base_Fare', 'Per_Km_Rate', 'Per_Minute_Rate', 'Trip_Duration_Minutes',
                      'Trip_Price']
categorical_features = ['Time_of_Day',  'Day_of_Week', 'Weather', 'Base_Fare']

"""### Categorical Features"""

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_category)
count.plot(kind='bar', title=feature);

"""Data menunjukkan bahwa waktu sore (Afternoon) lebih dominan dibandingkan waktu lainnya. Ini bisa menunjukkan bahwa sebagian besar aktivitas perjalanan taxi terjadi pada sore hari."""

feature = categorical_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_category)
count.plot(kind='bar', title=feature);

"""Dapat disimpulkan sangat jarang terdapat penumpang yang menggunakan taxi pada saat weekend, yang mana hanya sekitar 29,7 %"""

feature = categorical_features[2]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_category = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_category)
count.plot(kind='bar', title=feature);

"""Hampir tidak ada yang menggunakan taxi saat salju (snow), sebagian besar memilih cuaca yang terang.

### Numerical Features
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""- Mayoritas perjalanan taxi memiliki jarak antara 0-20 km
- Jumlah penumpang relatif merata di antara nilai 1 hingga 4 penumpang.
- Tarif dasar mayoritas berkisar antara 2.0-5.0
- Harga perjalanan membentuk distribusi normal dengan sedikit right-skewed

## Exploratory Data Analysis - Multivariate Analysis

### Categorical Features

Mengecek rata-rata Trip_Price terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap Trip_Price.
"""

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="Trip_Price", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'Trip_Price' Relatif terhadap - {}".format(col))

"""Berdasarkan Time of Day (Waktu):


- Harga perjalanan cenderung konsisten di semua waktu (morning, afternoon, evening, night)
- Rata-rata harga berkisar antara 50-52
- Variasi harga antar waktu sangat kecil, menunjukkan tidak ada perbedaan tarif signifikan berdasarkan waktu
- Ini bisa menjadi indikasi bahwa perusahaan taxi tidak menerapkan surge pricing berdasarkan waktu


Berdasarkan Day of Week (Hari):


- Terdapat dua kategori: Weekday dan Weekend
- Rata-rata harga di weekday dan weekend hampir sama (sekitar 50-52)
- Tidak ada perbedaan pricing yang signifikan antara hari kerja dan akhir pekan
- Menunjukkan kebijakan harga yang konsisten sepanjang minggu


Berdasarkan Traffic Conditions (Kondisi Lalu Lintas):


- Tiga kategori: Low, Medium, High
- Rata-rata harga relatif sama untuk semua kondisi lalu lintas (sekitar 50-52)
- Kondisi lalu lintas tidak mempengaruhi harga secara signifikan
- Ini menunjukkan bahwa tarif lebih didasarkan pada jarak dan waktu daripada kondisi lalu lintas


Berdasarkan Weather (Cuaca):


- Tiga kondisi cuaca: Clear, Rain, Snow
- Rata-rata harga konsisten di sekitar 50-52 untuk semua kondisi cuaca
- Tidak ada premium pricing untuk kondisi cuaca buruk
- Menunjukkan kebijakan harga yang fair tanpa mengambil keuntungan dari kondisi cuaca

### Numerical Features
Mengamati hubungan antara fitur numerik menggunakan fungsi pairplot() dan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr().
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""Pada pola sebaran data grafik pairplot, terlihat ‘Trip_Distance_km’, ‘Per_Km_Rate’, ‘Per_Minute_Rate’, dan ‘Trip_Duration_Minutes’ memiliki korelasi yang tinggi dengan fitur "Trip_Price". Sedangkan kedua fitur lainnya yaitu 'Passenger_Count' dan 'Base_Fare' terlihat memiliki korelasi yang lemah karena sebarannya tidak membentuk pola."""

# Mengamati hubungan antar fitur numerik dengan fungsi corr()
plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""'Trip_Distance_km' memiliki korelasi positif yang kuat (0.68), sedangkan 'Passenger_Count' dan 'Base_Fare' memiliki korelasi yang sangat lemah. Sehingga, kedua fitur tersebut dapat di-drop"""

df.drop(['Passenger_Count', 'Base_Fare'], inplace=True, axis=1)
df.head()

"""# Data Preparation

## Encoding Fitur Kategori
Fitur kategorikal diubah menjadi bentuk numerik menggunakan one-hot encoding
"""

from sklearn.preprocessing import  OneHotEncoder
df = pd.concat([df, pd.get_dummies(df['Time_of_Day'], prefix='Time_of_Day')],axis=1)
df = pd.concat([df, pd.get_dummies(df['Day_of_Week'], prefix='Day_of_Week')],axis=1)
df = pd.concat([df, pd.get_dummies(df['Traffic_Conditions'], prefix='Traffic_Conditions')],axis=1)
df = pd.concat([df, pd.get_dummies(df['Weather'], prefix='Weather')],axis=1)
df.drop(['Time_of_Day','Day_of_Week','Traffic_Conditions', 'Weather'], axis=1, inplace=True)
df.head()

"""## Reduksi Dimensi
Teknik reduksi (pengurangan) dimensi adalah prosedur yang mengurangi jumlah fitur dengan tetap mempertahankan informasi pada data
"""

sns.pairplot(df[['Trip_Distance_km',	'Per_Km_Rate',	'Per_Minute_Rate',	'Trip_Duration_Minutes']], plot_kws={"s": 4});

"""Seperti yang terlihat pada pairplot di atas, dapat disimpulkan bahwa antar fitur memiliki korelasi yang rendah. Karna itu, pengurangan dimensi tidak cocok dilakukan dengan alasan :
- Tidak ada multikolinearitas yang tinggi antar variabel
- Setiap fitur memberikan informasi yang cukup unik
- Korelasi tertinggi hanya 0.68 (Trip_Distance_km dengan Trip_Price)

## Train-Test-Split
Menggunakan proporsi pembagian sebesar 80:20 dengan fungsi train_test_split dari sklearn.
"""

from sklearn.model_selection import train_test_split

X = df.drop(["Trip_Price"],axis =1)
y = df["Trip_Price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi
Standarisasi dilakukan untuk mengubah data sehingga memiliki mean 0 dan standar deviasi 1.
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['Trip_Distance_km',	'Per_Km_Rate',	'Per_Minute_Rate',	'Trip_Duration_Minutes']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""sekarang nilai mean = 0 dan standar deviasi ≈ 1.

# Model Development

Membuat tiga buah model machine learning dangan algoritma berikut:

- K-Nearest Neighbor (KNN)
- Random Forest
- Boosting Algorithm.
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""## K-Nearest Neighbor (KNN)"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""## Random Forest"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""## Boosting Algorithm"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# Evaluasi Model

Melakukan proses scaling pada data latih untuk menghindari kebocoran data
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

""" Evaluasi ketiga model dengan metrik MSE"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model Random Forest (RF) memberikan nilai eror yang paling kecil. Sedangkan model dengan algoritma Boosting memiliki eror yang paling besar. Sehingga model RF yang akan kita pilih sebagai model terbaik untuk melakukan prediksi harga taxi.

Untuk mengujinya, prediksi menggunakan beberapa harga dari data test
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Terlihat bahwa prediksi dengan Random Forest (RF) memberikan hasil yang paling mendekati"""